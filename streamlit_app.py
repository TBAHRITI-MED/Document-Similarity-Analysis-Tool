import streamlit as st
import re
import numpy as np
import pandas as pd
from scipy.spatial.distance import pdist, squareform, braycurtis
from scipy.special import kl_div
from sklearn.feature_extraction.text import CountVectorizer
from scipy.spatial.distance import cdist
from sklearn.preprocessing import normalize
st.set_page_config(page_title="Analyse de similarit√© de documents", page_icon="üìÑ", layout="wide")

# 1. Diviser le texte en phrases
def split_into_sentences(text):
    sentences = re.split(r'(?<=[.!?])\s+', text.strip())
    return sentences

# 2. Pr√©traitement du texte
def preprocess_text(sentences):
    unique_tokens = set()
    for sentence in sentences:
        tokens = re.findall(r'\b\w+\b', sentence.lower())
        unique_tokens.update(tokens)
    return sorted(unique_tokens)

# 3. Cr√©er la matrice binaire et la matrice d'occurrences avec normalisation
def create_matrices(sentences, unique_tokens, normalization_type):
    binary_matrix = []
    occurrence_matrix = []
    
    for sentence in sentences:
        tokens = re.findall(r'\b\w+\b', sentence.lower())
        binary_row = [1 if token in tokens else 0 for token in unique_tokens]
        binary_matrix.append(binary_row)
        occurrence_row = [tokens.count(token) for token in unique_tokens]
        occurrence_matrix.append(occurrence_row)

    binary_matrix = np.array(binary_matrix)
    occurrence_matrix = np.array(occurrence_matrix)

    # Appliquer la normalisation choisie
    if normalization_type == "Probabilit√©":
        occurrence_matrix = occurrence_matrix / occurrence_matrix.sum(axis=1, keepdims=True)
    elif normalization_type == "L2":
        occurrence_matrix = normalize(occurrence_matrix, norm='l2')

    return binary_matrix, occurrence_matrix

# 4. Calculer la distance de Manhattan
def calculate_manhattan_distance(matrix):
    return squareform(pdist(matrix, metric='cityblock'))

# 5. Calculer la distance euclidienne
def calculate_euclidean_distance(matrix):
    return squareform(pdist(matrix, metric='euclidean'))

# 6. Calculer la distance de Jaccard
def calculate_jaccard_distance(binary_matrix):
    jaccard_distances = pdist(binary_matrix, metric='jaccard')
    return squareform(jaccard_distances)

# 7. Calculer la distance de Hamming
def calculate_hamming_distance(binary_matrix):
    hamming_distances = pdist(binary_matrix, metric='hamming')
    return squareform(hamming_distances)

# 8. Calculer la distance Bray-Curtis
def calculate_bray_curtis_distance(matrix):
    bray_curtis_distances = pdist(matrix, metric=braycurtis)
    return squareform(bray_curtis_distances)


def calculate_kl_divergence(p, q):
    return np.sum(kl_div(p, q))
# 9. Calculer la distance Kullback-Leibler
def calculate_kullback_leibler_distance(matrix):
    # Ajout de petites constantes pour √©viter la division par z√©ro
    matrix = np.clip(matrix, 1e-10, None)  # Clipper les valeurs
    kl_distances = squareform(pdist(matrix, metric=lambda u, v: np.sum(kl_div(u, v))))
    return kl_distances

# 10. Calculer la distance de Cosinus
def calculate_cosine_distance(matrix):
    """Calcule la distance de Cosinus entre les documents."""
    return squareform(pdist(matrix, metric='cosine'))

# 10. Cr√©er la matrice de similarit√©
def calculate_similarity_matrix(distance_matrix):
    max_distance = np.max(distance_matrix)
    return 1 - (distance_matrix / max_distance)

def K_plus_proches_documents(doc_requete, k, similarity_matrix, sentences):
    similarites = similarity_matrix[doc_requete]
    similarites_idx = [(i, similarites[i]) for i in range(len(similarites)) if i != doc_requete]
    similarites_idx.sort(key=lambda x: x[1], reverse=True)
    
    # R√©cup√©rer les k documents les plus similaires avec leurs phrases
    return [(idx, similarity, sentences[idx]) for idx, similarity in similarites_idx[:k]]

# Titre de l'application
st.title("Analyse de similarit√© de documents")

# Barre lat√©rale
st.sidebar.subheader("Param√®tres de configuration")
# Ajout d'une description
st.sidebar.write("""
    **Instructions :** S√©lectionnez les options ci-dessus pour configurer l'analyse de similarit√© des documents. 
""")
# Choix de la langue
langue = st.sidebar.radio("Choisissez la langue du texte :", ("Fran√ßais", "Anglais"))

# Choix du descripteur et de la normalisation
descripteur = st.sidebar.selectbox("Choisissez le descripteur √† utiliser :", 
                                    ["Binaire", "Occurrence"])

normalization_type = st.sidebar.selectbox("Choisissez la m√©thode de normalisation :", 
                                           ["Aucune", "Probabilit√©", "L2"])

# Choix de la m√©trique de distance
distance_type = st.sidebar.selectbox("Choisissez la m√©trique de distance :", 
                                     
                                      ["Manhattan", "Euclidienne", "Jaccard", "Hamming", "Bray-Curtis", "Kullback-Leibler", "Cosinus"])
 
st.sidebar.write("""
    **Vous pouvez entrer votre texte manuellement ou en t√©l√©chargeant un fichier .txt.**
""")

# M√©thode d'entr√©e de texte
input_mode = st.sidebar.radio("Comment voulez-vous entrer le texte ?", 
                               ("R√©daction manuelle", "D√©poser un fichier .txt"))



# Zone de texte pour la r√©daction manuelle ou fichier
if input_mode == "R√©daction manuelle":
    chiraq_text = st.text_area("R√©digez ou collez votre texte ici :")
else:
    uploaded_file = st.file_uploader("D√©posez votre fichier texte ici", type="txt")
    if uploaded_file is not None:
        chiraq_text = uploaded_file.read().decode("utf-8")
    else:
        chiraq_text = """La confiance que vous venez de me t√©moigner, je veux y r√©pondre en m'engageant dans l'action avec d√©termination.
Mes chers compatriotes de m√©tropole, d'outre-mer et de l'√©tranger,
Nous venons de vivre un temps de grave inqui√©tude pour la Nation.
Mais ce soir, dans un grand √©lan la France a r√©affirm√© son attachement aux valeurs de la R√©publique.
Je salue la France, fid√®le √† elle-m√™me, fid√®le √† ses grands id√©aux, fid√®le √† sa vocation universelle et humaniste.
Je salue la France qui, comme toujours dans les moments difficiles, sait se retrouver sur l'essentiel. Je salue les Fran√ßaises et les Fran√ßais √©pris de solidarit√© et de libert√©, soucieux de s'ouvrir √† l'Europe et au monde, tourn√©s vers l'avenir.
J'ai entendu et compris votre appel pour que la R√©publique vive, pour que la Nation se rassemble, pour que la politique change. Tout dans l'action qui sera conduite, devra r√©pondre √† cet appel et s'inspirer d'une exigence de service et d'√©coute pour chaque Fran√ßaise et chaque Fran√ßais.
Ce soir, je veux vous dire aussi mon √©motion et le sentiment que j'ai de la responsabilit√© qui m'incombe.
Votre choix d'aujourd'hui est un choix fondateur, un choix qui renouvelle notre pacte r√©publicain. Ce choix m'oblige comme il oblige chaque responsable de notre pays. Chacun mesure bien, √† l'aune de notre histoire, la force de ce moment exceptionnel.
Votre d√©cision, vous l'avez prise en conscience, en d√©passant les clivages traditionnels, et, pour certains d'entre vous, en allant au-del√† m√™me de vos pr√©f√©rences personnelles ou politiques.
La confiance que vous venez de me t√©moigner, je veux y r√©pondre en m'engageant dans l'action avec d√©termination.
Pr√©sident de tous les Fran√ßais, je veux y r√©pondre dans un esprit de rassemblement. Je veux mettre la R√©publique au service de tous. Je veux que les valeurs de libert√©, d'√©galit√© et de fraternit√© reprennent toute leur place dans la vie de chacune et de chacun d'entre nous.
La libert√©, c'est la s√©curit√©, la lutte contre la violence, le refus de l'impunit√©. Faire reculer l'ins√©curit√© est la premi√®re priorit√© de l'Etat pour les temps √† venir.
La libert√©, c'est aussi la reconnaissance du travail et du m√©rite, la r√©duction des charges et des imp√¥ts.
L'√©galit√©, c'est le refus de toute discrimination, ce sont les m√™mes droits et les m√™mes devoirs pour tous.
La fraternit√©, c'est sauvegarder les retraites. C'est aider les familles √† jouer pleinement leur r√¥le. C'est faire en sorte que personne n'√©prouve plus le sentiment d'√™tre laiss√© pour compte.
La France, forte de sa coh√©sion sociale et de son dynamisme √©conomique, portera en Europe et dans le monde l'ambition de la paix, des libert√©s et de la solidarit√©.
Dans les prochains jours, je mettrai en place un gouvernement de mission, un gouvernement qui aura pour seule t√¢che de r√©pondre √† vos pr√©occupations et d'apporter des solutions √† des probl√®mes trop longtemps n√©glig√©s. Son premier devoir sera de r√©tablir l'autorit√© de l'Etat pour r√©pondre √† l'exigence de s√©curit√©, et de mettre la France sur un nouveau chemin de croissance et d'emploi.
C'est par une action forte et d√©termin√©e, c'est par la solidarit√© de la Nation, c'est par l'efficacit√© des r√©sultats obtenus, que nous pourrons lutter contre l'intol√©rance, faire reculer l'extr√©misme, garantir la vitalit√© de notre d√©mocratie. Cette exigence s'impose √† chacun d'entre nous. Elle impliquera, au cours des prochaines ann√©es, vigilance et mobilisation de la part de tous.
Mes chers compatriotes,
Le mandat que vous m'avez confi√©, je l'exercerai dans un esprit d'ouverture et de concorde, avec pour exigence l'unit√© de la R√©publique, la coh√©sion de la Nation et le respect de l'autorit√© de l'Etat.
Les jours que nous venons de vivre ont ranim√© la vigueur nationale, la vigueur de l'id√©al d√©mocratique fran√ßais. Ils ont exprim√© une autre id√©e de la politique, une autre id√©e de la citoyennet√©.
Chacune et chacun d'entre vous, conscient de ses responsabilit√©s, par un choix de libert√©, a contribu√©, ce soir, √† forger le destin de la France.
Il y a l√† un espoir qui ne demande qu'√† grandir, un espoir que je veux servir.
Vive la R√©publique !
Vive la France !"""

# Traitement si le texte est fourni
if chiraq_text:
 with st.spinner("Traitement en cours..."):
    sentences = split_into_sentences(chiraq_text)
    st.write(f"Le texte contient {len(sentences)} phrases.")
    
    unique_tokens = preprocess_text(sentences)
    binary_matrix, occurrence_matrix = create_matrices(sentences, unique_tokens, normalization_type)

    # S√©lectionner la matrice en fonction du descripteur choisi
    if descripteur == "Binaire":
        matrix = binary_matrix
    else:
        matrix = occurrence_matrix

    # Calcul de la distance selon le choix de l'utilisateur
    if distance_type == "Manhattan":
        distance_matrix = calculate_manhattan_distance(matrix)
    elif distance_type == "Euclidienne":
        distance_matrix = calculate_euclidean_distance(matrix)
    elif distance_type == "Jaccard":
        distance_matrix = calculate_jaccard_distance(binary_matrix)
    elif distance_type == "Hamming":
        distance_matrix = calculate_hamming_distance(binary_matrix)
    elif distance_type == "Bray-Curtis":
        distance_matrix = calculate_bray_curtis_distance(matrix)
    elif distance_type == "Kullback-Leibler":
        distance_matrix = calculate_kullback_leibler_distance(matrix)
    elif distance_type == "Cosinus":
        distance_matrix = calculate_cosine_distance(matrix)
    
    # Afficher la matrice de distance sous forme de DataFrame
    distance_df = pd.DataFrame(distance_matrix, 
                               columns=[f'Doc {i+1}' for i in range(len(sentences))],
                               index=[f'Doc {i+1}' for i in range(len(sentences))])
    st.write("Matrice de distance :")
    st.dataframe(distance_df)

    # Calculer et afficher la matrice de similarit√©
    similarity_matrix = calculate_similarity_matrix(distance_matrix)
    similarity_df = pd.DataFrame(similarity_matrix, 
                                 columns=[f'Doc {i+1}' for i in range(len(sentences))],
                                 index=[f'Doc {i+1}' for i in range(len(sentences))])
    st.write("Matrice de similarit√© :")
    st.dataframe(similarity_df)
    
    # Choisir un document pour trouver les plus proches
    # Affichage des documents avec des extraits de phrases
options_docs = [
    f"Document {i + 1}: {sentences[i][:100]}..." if len(sentences[i]) > 100 else f"Document {i + 1}: {sentences[i]}"
    for i in range(len(sentences))
]
st.write(options_docs) 

###################
from sklearn.feature_extraction.text import TfidfVectorizer
def calculer_similarite(phrase, documents):
    vectorizer = TfidfVectorizer()
    # Fusionner la phrase recherch√©e et les documents
    corpus = [phrase] + documents
    tfidf_matrix = vectorizer.fit_transform(corpus)
    
    # Calcul de la similarit√© entre la phrase et chaque document
    similarites = (tfidf_matrix * tfidf_matrix.T).A[0][1:]
    return similarites
##########
# Entr√©e pour le num√©ro de document
doc_requete = st.number_input("Entrez le num√©ro du document (1 √† N) :", 
                              min_value=1, max_value=len(sentences), step=1) - 1
k = st.slider("Choisissez le nombre de documents similaires √† afficher :", 1, len(sentences)-1, 3)
# Entr√©e pour rechercher une phrase dans les documents
phrase_recherche = st.text_input("Entrez une phrase pour rechercher dans les documents :")

# Calculer les documents les plus similaires si la phrase de recherche est remplie
if phrase_recherche:
    similarites_recherche = calculer_similarite(phrase_recherche, sentences)
    
    # Trier les documents par similarit√©
    indices_similaires = sorted(range(len(similarites_recherche)), key=lambda i: similarites_recherche[i], reverse=True)
    
    st.write(f"Les {k} documents les plus similaires √† la phrase recherch√©e :")
    for idx in indices_similaires[:k]:
        st.write(f"Document {idx + 1} avec similarit√© de {similarites_recherche[idx]:.4f} : {sentences[idx][:200]}...")
# Calculer les documents les plus similaires
if st.button("Trouver les documents similaires"):
    k_plus_proches = K_plus_proches_documents(doc_requete, k, similarity_matrix, sentences)
    st.write(f"Les {k} documents les plus similaires au document {doc_requete + 1} :")
    for idx, sim, phrase in k_plus_proches:
        st.write(f"Document {idx + 1} avec similarit√© de {sim:.4f} : {phrase[:200]}...")  # Afficher un extrait de 200 caract√®res de la phrase

    




# Fonction pour calculer TF-IDF_New pour un document
def TF_IDF_New(liste_mots_differents_corpus, document, df):
    """
    Cette fonction retourne un vecteur caract√©ristique du document de taille nb_mots_differents_corpus,
    o√π chaque bin contient le score TF-IDF_new.
    - liste_mots_differents_corpus : liste des mots uniques du corpus
    - document : liste de mots du document √† analyser
    - df : S√©rie ou dictionnaire donnant le nombre de documents contenant chaque mot (Document Frequency)
    """
    # Cr√©er une s√©rie pour le calcul de la fr√©quence des mots dans le document
    tf_doc = pd.Series(document).value_counts(normalize=True)

    # Initialiser le vecteur TF-IDF_new avec des z√©ros pour chaque mot unique du corpus
    tfidf_new_vector = pd.Series(0, index=liste_mots_differents_corpus)

    # Calculer le TF-IDF pour chaque mot du document
    for mot in document:
        if mot in liste_mots_differents_corpus:
            # IDF est calcul√© comme le log du ratio entre le nombre total de documents et le nombre de documents contenant le mot
            idf = np.log10(len(df) / (1 + df.get(mot, 0)))
            tfidf_new_vector[mot] = tf_doc.get(mot, 0) * idf

    return tfidf_new_vector


# Fonction pour cr√©er des matrices de fr√©quence
def create_matrices(sentences):
    vectorizer_binary = CountVectorizer(binary=True)
    vectorizer_occurrence = CountVectorizer()
    
    X_binary = vectorizer_binary.fit_transform(sentences)
    X_occ = vectorizer_occurrence.fit_transform(sentences)

    terms = vectorizer_occurrence.get_feature_names_out()

    # TF binaire
    tf_binary = pd.DataFrame(X_binary.toarray(), columns=terms, index=[f'Doc {i+1}' for i in range(len(sentences))])

    # TF occurrence
    tf_occ = pd.DataFrame(X_occ.toarray(), columns=terms, index=[f'Doc {i+1}' for i in range(len(sentences))])

    # TF occurrence normalis√©
    tf_occ_normalized = tf_occ.div(tf_occ.sum(axis=1), axis=0)

    return tf_binary, tf_occ, tf_occ_normalized, terms

# Fonction pour calculer le TF-IDF manuellement
def calculate_tfidf(tf_occ, num_documents):
    # DF (Document Frequency)
    df = (tf_occ > 0).sum(axis=0)

    # IDF (Inverse Document Frequency)
    idf = np.log10(num_documents / df)

    # Calculer les matrices TF-IDF
    tfidf_binary = tf_binary * idf.values
    tfidf_occ = tf_occ * idf.values
    tfidf_occ_normalized = tf_occ_normalized * idf.values

    return tfidf_binary, tfidf_occ, tfidf_occ_normalized

# Interface utilisateur Streamlit
st.title("Analyse de similarit√© de documents avec TF-IDF")


if chiraq_text:
    sentences = split_into_sentences(chiraq_text)
    st.write(f"Le texte contient {len(sentences)} phrases.")

    unique_tokens = preprocess_text(sentences)
    tf_binary, tf_occ, tf_occ_normalized, terms = create_matrices(sentences)

    # Calcul du TF-IDF
    tfidf_binary, tfidf_occ, tfidf_occ_normalized = calculate_tfidf(tf_occ, len(sentences))
    
    
    
################################################################################################
    # Calcul du DF (Document Frequency) pour chaque mot
    df = (tf_occ > 0).sum(axis=0)
    sentences = split_into_sentences(chiraq_text)
    # Interface utilisateur pour s√©lectionner une phrase/document
    selected_sentence = st.selectbox(
     "S√©lectionnez une phrase pour calculer le vecteur TF-IDF_New :",
     options=sentences,
     format_func=lambda x: x[:100] + "..." if len(x) > 100 else x  # Afficher une partie de la phrase si elle est longue
    )

# Calcul du TF-IDF_New pour la phrase s√©lectionn√©e
    if selected_sentence:
     tfidf_new_vector = TF_IDF_New(terms, selected_sentence.split(), df)
     st.write("Vecteur TF-IDF_New pour la phrase s√©lectionn√©e :")
     st.dataframe(tfidf_new_vector)

################################################################################################


    # Afficher les matrices TF-IDF
    st.write("**Matrice TF-IDF Binaire :**")
    st.dataframe(tfidf_binary)

    st.write("**Matrice TF-IDF Occurrence :**")
    st.dataframe(tfidf_occ)

    st.write("**Matrice TF-IDF Occurrence Normalis√©e :**")
    st.dataframe(tfidf_occ_normalized)

    # Calcul des distances
    distance_l1_binary = cdist(tfidf_binary, tfidf_binary, metric='cityblock')
    distance_l1_occ = cdist(tfidf_occ, tfidf_occ, metric='cityblock')
    distance_l1_occ_normalized = cdist(tfidf_occ_normalized, tfidf_occ_normalized, metric='cityblock')

    distance_l2_binary = cdist(tfidf_binary, tfidf_binary, metric='euclidean')
    distance_l2_occ = cdist(tfidf_occ, tfidf_occ, metric='euclidean')
    distance_l2_occ_normalized = cdist(tfidf_occ_normalized, tfidf_occ_normalized, metric='euclidean')

    distance_bray_curtis_binary = cdist(tfidf_binary, tfidf_binary, metric='braycurtis')
    distance_bray_curtis_occ = cdist(tfidf_occ, tfidf_occ, metric='braycurtis')
    distance_bray_curtis_occ_normalized = cdist(tfidf_occ_normalized, tfidf_occ_normalized, metric='braycurtis')

    # Afficher les distances L1
    st.write("****Distance L1 Binaire :****")
    st.dataframe(distance_l1_binary)

    st.write("**Distance L1 Occurrence :**")
    st.dataframe(distance_l1_occ)

    st.write("**Distance L1 Occurrence Normalis√©e **:")
    st.dataframe(distance_l1_occ_normalized)

    # Afficher les distances L2
    st.write("**Distance L2 (Euclidienne) Binaire **:")
    st.dataframe(distance_l2_binary)

    st.write("**Distance L2 (Euclidienne) Occurrence **:")
    st.dataframe(distance_l2_occ)

    st.write("**Distance L2 (Euclidienne) Occurrence Normalis√©e **:")
    st.dataframe(distance_l2_occ_normalized)

    # Afficher les distances Bray-Curtis
    st.write("**Distance Bray-Curtis Binaire **:")
    st.dataframe(distance_bray_curtis_binary)

    st.write("**Distance Bray-Curtis Occurrence **:")
    st.dataframe(distance_bray_curtis_occ)

    st.write("**Distance Bray-Curtis Occurrence Normalis√©e :**")
    st.dataframe(distance_bray_curtis_occ_normalized)
