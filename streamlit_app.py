import streamlit as st
import re
import numpy as np
import pandas as pd
from scipy.spatial.distance import pdist, squareform, braycurtis
from scipy.special import kl_div
from sklearn.feature_extraction.text import CountVectorizer
from scipy.spatial.distance import cdist
from sklearn.preprocessing import normalize
st.set_page_config(page_title="Analyse de similaritÃ© de documents", page_icon="ðŸ“„", layout="wide")

# 1. Diviser le texte en phrases
def split_into_sentences(text):
    sentences = re.split(r'(?<=[.!?])\s+', text.strip())
    return sentences

# 2. PrÃ©traitement du texte
def preprocess_text(sentences):
    unique_tokens = set()
    for sentence in sentences:
        tokens = re.findall(r'\b\w+\b', sentence.lower())
        unique_tokens.update(tokens)
    return sorted(unique_tokens)

# 3. CrÃ©er la matrice binaire et la matrice d'occurrences avec normalisation
def create_matrices(sentences, unique_tokens, normalization_type):
    binary_matrix = []
    occurrence_matrix = []
    
    for sentence in sentences:
        tokens = re.findall(r'\b\w+\b', sentence.lower())
        binary_row = [1 if token in tokens else 0 for token in unique_tokens]
        binary_matrix.append(binary_row)
        occurrence_row = [tokens.count(token) for token in unique_tokens]
        occurrence_matrix.append(occurrence_row)

    binary_matrix = np.array(binary_matrix)
    occurrence_matrix = np.array(occurrence_matrix)

    # Appliquer la normalisation choisie
    if normalization_type == "ProbabilitÃ©":
        occurrence_matrix = occurrence_matrix / occurrence_matrix.sum(axis=1, keepdims=True)
    elif normalization_type == "L2":
        occurrence_matrix = normalize(occurrence_matrix, norm='l2')

    return binary_matrix, occurrence_matrix

# 4. Calculer la distance de Manhattan
def calculate_manhattan_distance(matrix):
    return squareform(pdist(matrix, metric='cityblock'))

# 5. Calculer la distance euclidienne
def calculate_euclidean_distance(matrix):
    return squareform(pdist(matrix, metric='euclidean'))

# 6. Calculer la distance de Jaccard
def calculate_jaccard_distance(binary_matrix):
    jaccard_distances = pdist(binary_matrix, metric='jaccard')
    return squareform(jaccard_distances)

# 7. Calculer la distance de Hamming
def calculate_hamming_distance(binary_matrix):
    hamming_distances = pdist(binary_matrix, metric='hamming')
    return squareform(hamming_distances)

# 8. Calculer la distance Bray-Curtis
def calculate_bray_curtis_distance(matrix):
    bray_curtis_distances = pdist(matrix, metric=braycurtis)
    return squareform(bray_curtis_distances)


def calculate_kl_divergence(p, q):
    return np.sum(kl_div(p, q))
# 9. Calculer la distance Kullback-Leibler
def calculate_kullback_leibler_distance(matrix):
    # Ajout de petites constantes pour Ã©viter la division par zÃ©ro
    matrix = np.clip(matrix, 1e-10, None)  # Clipper les valeurs
    kl_distances = squareform(pdist(matrix, metric=lambda u, v: np.sum(kl_div(u, v))))
    return kl_distances

# 10. Calculer la distance de Cosinus
def calculate_cosine_distance(matrix):
    """Calcule la distance de Cosinus entre les documents."""
    return squareform(pdist(matrix, metric='cosine'))

# 10. CrÃ©er la matrice de similaritÃ©
def calculate_similarity_matrix(distance_matrix):
    max_distance = np.max(distance_matrix)
    return 1 - (distance_matrix / max_distance)

def K_plus_proches_documents(doc_requete, k, similarity_matrix, sentences):
    similarites = similarity_matrix[doc_requete]
    similarites_idx = [(i, similarites[i]) for i in range(len(similarites)) if i != doc_requete]
    similarites_idx.sort(key=lambda x: x[1], reverse=True)
    
    # RÃ©cupÃ©rer les k documents les plus similaires avec leurs phrases
    return [(idx, similarity, sentences[idx]) for idx, similarity in similarites_idx[:k]]

# Titre de l'application
st.title("Analyse de similaritÃ© de documents")

# Barre latÃ©rale
st.sidebar.subheader("ParamÃ¨tres de configuration")
# Ajout d'une description
st.sidebar.write("""
    **Instructions :** SÃ©lectionnez les options ci-dessus pour configurer l'analyse de similaritÃ© des documents. 
""")
# Choix de la langue
langue = st.sidebar.radio("Choisissez la langue du texte :", ("FranÃ§ais", "Anglais"))

# Choix du descripteur et de la normalisation
descripteur = st.sidebar.selectbox("Choisissez le descripteur Ã  utiliser :", 
                                    ["Binaire", "Occurrence"])

normalization_type = st.sidebar.selectbox("Choisissez la mÃ©thode de normalisation :", 
                                           ["Aucune", "ProbabilitÃ©", "L2"])

# Choix de la mÃ©trique de distance
distance_type = st.sidebar.selectbox("Choisissez la mÃ©trique de distance :", 
                                     
                                      ["Manhattan", "Euclidienne", "Jaccard", "Hamming", "Bray-Curtis", "Kullback-Leibler", "Cosinus"])
 
st.sidebar.write("""
    **Vous pouvez entrer votre texte manuellement ou en tÃ©lÃ©chargeant un fichier .txt.**
""")

# MÃ©thode d'entrÃ©e de texte
input_mode = st.sidebar.radio("Comment voulez-vous entrer le texte ?", 
                               ("RÃ©daction manuelle", "DÃ©poser un fichier .txt"))



# Zone de texte pour la rÃ©daction manuelle ou fichier
if input_mode == "RÃ©daction manuelle":
    chiraq_text = st.text_area("RÃ©digez ou collez votre texte ici :")
else:
    uploaded_file = st.file_uploader("DÃ©posez votre fichier texte ici", type="txt")
    if uploaded_file is not None:
        chiraq_text = uploaded_file.read().decode("utf-8")
    else:
        chiraq_text = """La confiance que vous venez de me tÃ©moigner, je veux y rÃ©pondre en m'engageant dans l'action avec dÃ©termination.
Mes chers compatriotes de mÃ©tropole, d'outre-mer et de l'Ã©tranger,
Nous venons de vivre un temps de grave inquiÃ©tude pour la Nation.
Mais ce soir, dans un grand Ã©lan la France a rÃ©affirmÃ© son attachement aux valeurs de la RÃ©publique.
Je salue la France, fidÃ¨le Ã  elle-mÃªme, fidÃ¨le Ã  ses grands idÃ©aux, fidÃ¨le Ã  sa vocation universelle et humaniste.
Je salue la France qui, comme toujours dans les moments difficiles, sait se retrouver sur l'essentiel. Je salue les FranÃ§aises et les FranÃ§ais Ã©pris de solidaritÃ© et de libertÃ©, soucieux de s'ouvrir Ã  l'Europe et au monde, tournÃ©s vers l'avenir.
J'ai entendu et compris votre appel pour que la RÃ©publique vive, pour que la Nation se rassemble, pour que la politique change. Tout dans l'action qui sera conduite, devra rÃ©pondre Ã  cet appel et s'inspirer d'une exigence de service et d'Ã©coute pour chaque FranÃ§aise et chaque FranÃ§ais.
Ce soir, je veux vous dire aussi mon Ã©motion et le sentiment que j'ai de la responsabilitÃ© qui m'incombe.
Votre choix d'aujourd'hui est un choix fondateur, un choix qui renouvelle notre pacte rÃ©publicain. Ce choix m'oblige comme il oblige chaque responsable de notre pays. Chacun mesure bien, Ã  l'aune de notre histoire, la force de ce moment exceptionnel.
Votre dÃ©cision, vous l'avez prise en conscience, en dÃ©passant les clivages traditionnels, et, pour certains d'entre vous, en allant au-delÃ  mÃªme de vos prÃ©fÃ©rences personnelles ou politiques.
La confiance que vous venez de me tÃ©moigner, je veux y rÃ©pondre en m'engageant dans l'action avec dÃ©termination.
PrÃ©sident de tous les FranÃ§ais, je veux y rÃ©pondre dans un esprit de rassemblement. Je veux mettre la RÃ©publique au service de tous. Je veux que les valeurs de libertÃ©, d'Ã©galitÃ© et de fraternitÃ© reprennent toute leur place dans la vie de chacune et de chacun d'entre nous.
La libertÃ©, c'est la sÃ©curitÃ©, la lutte contre la violence, le refus de l'impunitÃ©. Faire reculer l'insÃ©curitÃ© est la premiÃ¨re prioritÃ© de l'Etat pour les temps Ã  venir.
La libertÃ©, c'est aussi la reconnaissance du travail et du mÃ©rite, la rÃ©duction des charges et des impÃ´ts.
L'Ã©galitÃ©, c'est le refus de toute discrimination, ce sont les mÃªmes droits et les mÃªmes devoirs pour tous.
La fraternitÃ©, c'est sauvegarder les retraites. C'est aider les familles Ã  jouer pleinement leur rÃ´le. C'est faire en sorte que personne n'Ã©prouve plus le sentiment d'Ãªtre laissÃ© pour compte.
La France, forte de sa cohÃ©sion sociale et de son dynamisme Ã©conomique, portera en Europe et dans le monde l'ambition de la paix, des libertÃ©s et de la solidaritÃ©.
Dans les prochains jours, je mettrai en place un gouvernement de mission, un gouvernement qui aura pour seule tÃ¢che de rÃ©pondre Ã  vos prÃ©occupations et d'apporter des solutions Ã  des problÃ¨mes trop longtemps nÃ©gligÃ©s. Son premier devoir sera de rÃ©tablir l'autoritÃ© de l'Etat pour rÃ©pondre Ã  l'exigence de sÃ©curitÃ©, et de mettre la France sur un nouveau chemin de croissance et d'emploi.
C'est par une action forte et dÃ©terminÃ©e, c'est par la solidaritÃ© de la Nation, c'est par l'efficacitÃ© des rÃ©sultats obtenus, que nous pourrons lutter contre l'intolÃ©rance, faire reculer l'extrÃ©misme, garantir la vitalitÃ© de notre dÃ©mocratie. Cette exigence s'impose Ã  chacun d'entre nous. Elle impliquera, au cours des prochaines annÃ©es, vigilance et mobilisation de la part de tous.
Mes chers compatriotes,
Le mandat que vous m'avez confiÃ©, je l'exercerai dans un esprit d'ouverture et de concorde, avec pour exigence l'unitÃ© de la RÃ©publique, la cohÃ©sion de la Nation et le respect de l'autoritÃ© de l'Etat.
Les jours que nous venons de vivre ont ranimÃ© la vigueur nationale, la vigueur de l'idÃ©al dÃ©mocratique franÃ§ais. Ils ont exprimÃ© une autre idÃ©e de la politique, une autre idÃ©e de la citoyennetÃ©.
Chacune et chacun d'entre vous, conscient de ses responsabilitÃ©s, par un choix de libertÃ©, a contribuÃ©, ce soir, Ã  forger le destin de la France.
Il y a lÃ  un espoir qui ne demande qu'Ã  grandir, un espoir que je veux servir.
Vive la RÃ©publique !
Vive la France !"""

# Traitement si le texte est fourni
if chiraq_text:
 with st.spinner("Traitement en cours..."):
    sentences = split_into_sentences(chiraq_text)
    st.write(f"Le texte contient {len(sentences)} phrases.")
    
    unique_tokens = preprocess_text(sentences)
    binary_matrix, occurrence_matrix = create_matrices(sentences, unique_tokens, normalization_type)

    # SÃ©lectionner la matrice en fonction du descripteur choisi
    if descripteur == "Binaire":
        matrix = binary_matrix
    else:
        matrix = occurrence_matrix

    # Calcul de la distance selon le choix de l'utilisateur
    if distance_type == "Manhattan":
        distance_matrix = calculate_manhattan_distance(matrix)
    elif distance_type == "Euclidienne":
        distance_matrix = calculate_euclidean_distance(matrix)
    elif distance_type == "Jaccard":
        distance_matrix = calculate_jaccard_distance(binary_matrix)
    elif distance_type == "Hamming":
        distance_matrix = calculate_hamming_distance(binary_matrix)
    elif distance_type == "Bray-Curtis":
        distance_matrix = calculate_bray_curtis_distance(matrix)
    elif distance_type == "Kullback-Leibler":
        distance_matrix = calculate_kullback_leibler_distance(matrix)
    elif distance_type == "Cosinus":
        distance_matrix = calculate_cosine_distance(matrix)
    
    # Afficher la matrice de distance sous forme de DataFrame
    distance_df = pd.DataFrame(distance_matrix, 
                               columns=[f'Doc {i+1}' for i in range(len(sentences))],
                               index=[f'Doc {i+1}' for i in range(len(sentences))])
    st.write("Matrice de distance :")
    st.dataframe(distance_df)

    # Calculer et afficher la matrice de similaritÃ©
    similarity_matrix = calculate_similarity_matrix(distance_matrix)
    similarity_df = pd.DataFrame(similarity_matrix, 
                                 columns=[f'Doc {i+1}' for i in range(len(sentences))],
                                 index=[f'Doc {i+1}' for i in range(len(sentences))])
    st.write("Matrice de similaritÃ© :")
    st.dataframe(similarity_df)
    
    # Choisir un document pour trouver les plus proches
    # Affichage des documents avec des extraits de phrases
options_docs = [
    f"Document {i + 1}: {sentences[i][:100]}..." if len(sentences[i]) > 100 else f"Document {i + 1}: {sentences[i]}"
    for i in range(len(sentences))
]
st.write(options_docs) 

###################
from sklearn.feature_extraction.text import TfidfVectorizer
def calculer_similarite(phrase, documents):
    vectorizer = TfidfVectorizer()
    # Fusionner la phrase recherchÃ©e et les documents
    corpus = [phrase] + documents
    tfidf_matrix = vectorizer.fit_transform(corpus)
    
    # Calcul de la similaritÃ© entre la phrase et chaque document
    similarites = (tfidf_matrix * tfidf_matrix.T).A[0][1:]
    return similarites
##########
# EntrÃ©e pour le numÃ©ro de document
doc_requete = st.number_input("Entrez le numÃ©ro du document (1 Ã  N) :", 
                              min_value=1, max_value=len(sentences), step=1) - 1
k = st.slider("Choisissez le nombre de documents similaires Ã  afficher :", 1, len(sentences)-1, 3)
# EntrÃ©e pour rechercher une phrase dans les documents
phrase_recherche = st.text_input("Entrez une phrase pour rechercher dans les documents :")

# Calculer les documents les plus similaires si la phrase de recherche est remplie
if phrase_recherche:
    similarites_recherche = calculer_similarite(phrase_recherche, sentences)
    
    # Trier les documents par similaritÃ©
    indices_similaires = sorted(range(len(similarites_recherche)), key=lambda i: similarites_recherche[i], reverse=True)
    
    st.write(f"Les {k} documents les plus similaires Ã  la phrase recherchÃ©e :")
    for idx in indices_similaires[:k]:
        st.write(f"Document {idx + 1} avec similaritÃ© de {similarites_recherche[idx]:.4f} : {sentences[idx][:200]}...")
# Calculer les documents les plus similaires
if st.button("Trouver les documents similaires"):
    k_plus_proches = K_plus_proches_documents(doc_requete, k, similarity_matrix, sentences)
    st.write(f"Les {k} documents les plus similaires au document {doc_requete + 1} :")
    for idx, sim, phrase in k_plus_proches:
        st.write(f"Document {idx + 1} avec similaritÃ© de {sim:.4f} : {phrase[:200]}...")  # Afficher un extrait de 200 caractÃ¨res de la phrase

    




# Fonction pour calculer TF-IDF_New pour un document
def TF_IDF_New(liste_mots_differents_corpus, document, df):
    """
    Cette fonction retourne un vecteur caractÃ©ristique du document de taille nb_mots_differents_corpus,
    oÃ¹ chaque bin contient le score TF-IDF_new.
    - liste_mots_differents_corpus : liste des mots uniques du corpus
    - document : liste de mots du document Ã  analyser
    - df : SÃ©rie ou dictionnaire donnant le nombre de documents contenant chaque mot (Document Frequency)
    """
    # CrÃ©er une sÃ©rie pour le calcul de la frÃ©quence des mots dans le document
    tf_doc = pd.Series(document).value_counts(normalize=True)

    # Initialiser le vecteur TF-IDF_new avec des zÃ©ros pour chaque mot unique du corpus
    tfidf_new_vector = pd.Series(0, index=liste_mots_differents_corpus)

    # Calculer le TF-IDF pour chaque mot du document
    for mot in document:
        if mot in liste_mots_differents_corpus:
            # IDF est calculÃ© comme le log du ratio entre le nombre total de documents et le nombre de documents contenant le mot
            idf = np.log10(len(df) / (1 + df.get(mot, 0)))
            tfidf_new_vector[mot] = tf_doc.get(mot, 0) * idf

    return tfidf_new_vector


# Fonction pour crÃ©er des matrices de frÃ©quence
def create_matrices(sentences):
    vectorizer_binary = CountVectorizer(binary=True)
    vectorizer_occurrence = CountVectorizer()
    
    X_binary = vectorizer_binary.fit_transform(sentences)
    X_occ = vectorizer_occurrence.fit_transform(sentences)

    terms = vectorizer_occurrence.get_feature_names_out()

    # TF binaire
    tf_binary = pd.DataFrame(X_binary.toarray(), columns=terms, index=[f'Doc {i+1}' for i in range(len(sentences))])

    # TF occurrence
    tf_occ = pd.DataFrame(X_occ.toarray(), columns=terms, index=[f'Doc {i+1}' for i in range(len(sentences))])

    # TF occurrence normalisÃ©
    tf_occ_normalized = tf_occ.div(tf_occ.sum(axis=1), axis=0)

    return tf_binary, tf_occ, tf_occ_normalized, terms

# Fonction pour calculer le TF-IDF manuellement
def calculate_tfidf(tf_occ, num_documents):
    # DF (Document Frequency)
    df = (tf_occ > 0).sum(axis=0)

    # IDF (Inverse Document Frequency)
    idf = np.log10(num_documents / df)

    # Calculer les matrices TF-IDF
    tfidf_binary = tf_binary * idf.values
    tfidf_occ = tf_occ * idf.values
    tfidf_occ_normalized = tf_occ_normalized * idf.values

    return tfidf_binary, tfidf_occ, tfidf_occ_normalized

# Interface utilisateur Streamlit
st.title("Analyse de similaritÃ© de documents avec TF-IDF")


if chiraq_text:
    sentences = split_into_sentences(chiraq_text)
    st.write(f"Le texte contient {len(sentences)} phrases.")

    unique_tokens = preprocess_text(sentences)
    tf_binary, tf_occ, tf_occ_normalized, terms = create_matrices(sentences)

    # Calcul du TF-IDF
    tfidf_binary, tfidf_occ, tfidf_occ_normalized = calculate_tfidf(tf_occ, len(sentences))
    
    
    
################################################################################################
    # Calcul du DF (Document Frequency) pour chaque mot
    df = (tf_occ > 0).sum(axis=0)
    sentences = split_into_sentences(chiraq_text)
    # Interface utilisateur pour sÃ©lectionner une phrase/document
    selected_sentence = st.selectbox(
     "SÃ©lectionnez une phrase pour calculer le vecteur TF-IDF_New :",
     options=sentences,
     format_func=lambda x: x[:100] + "..." if len(x) > 100 else x  # Afficher une partie de la phrase si elle est longue
    )

# Calcul du TF-IDF_New pour la phrase sÃ©lectionnÃ©e
    if selected_sentence:
     tfidf_new_vector = TF_IDF_New(terms, selected_sentence.split(), df)
     st.write("Vecteur TF-IDF_New pour la phrase sÃ©lectionnÃ©e :")
     st.dataframe(tfidf_new_vector)

################################################################################################


    # Afficher les matrices TF-IDF
    st.write("**Matrice TF-IDF Binaire :**")
    st.dataframe(tfidf_binary)

    st.write("**Matrice TF-IDF Occurrence :**")
    st.dataframe(tfidf_occ)

    st.write("**Matrice TF-IDF Occurrence NormalisÃ©e :**")
    st.dataframe(tfidf_occ_normalized)

    # Calcul des distances
    distance_l1_binary = cdist(tfidf_binary, tfidf_binary, metric='cityblock')
    distance_l1_occ = cdist(tfidf_occ, tfidf_occ, metric='cityblock')
    distance_l1_occ_normalized = cdist(tfidf_occ_normalized, tfidf_occ_normalized, metric='cityblock')

    distance_l2_binary = cdist(tfidf_binary, tfidf_binary, metric='euclidean')
    distance_l2_occ = cdist(tfidf_occ, tfidf_occ, metric='euclidean')
    distance_l2_occ_normalized = cdist(tfidf_occ_normalized, tfidf_occ_normalized, metric='euclidean')

    distance_bray_curtis_binary = cdist(tfidf_binary, tfidf_binary, metric='braycurtis')
    distance_bray_curtis_occ = cdist(tfidf_occ, tfidf_occ, metric='braycurtis')
    distance_bray_curtis_occ_normalized = cdist(tfidf_occ_normalized, tfidf_occ_normalized, metric='braycurtis')

    # Afficher les distances L1
    st.write("****Distance L1 Binaire :****")
    st.dataframe(distance_l1_binary)

    st.write("**Distance L1 Occurrence :**")
    st.dataframe(distance_l1_occ)

    st.write("**Distance L1 Occurrence NormalisÃ©e **:")
    st.dataframe(distance_l1_occ_normalized)

    # Afficher les distances L2
    st.write("**Distance L2 (Euclidienne) Binaire **:")
    st.dataframe(distance_l2_binary)

    st.write("**Distance L2 (Euclidienne) Occurrence **:")
    st.dataframe(distance_l2_occ)

    st.write("**Distance L2 (Euclidienne) Occurrence NormalisÃ©e **:")
    st.dataframe(distance_l2_occ_normalized)

    # Afficher les distances Bray-Curtis
    st.write("**Distance Bray-Curtis Binaire **:")
    st.dataframe(distance_bray_curtis_binary)

    st.write("**Distance Bray-Curtis Occurrence **:")
    st.dataframe(distance_bray_curtis_occ)

    st.write("**Distance Bray-Curtis Occurrence NormalisÃ©e :**")
    st.dataframe(distance_bray_curtis_occ_normalized)
